å¢é‡ä»£ç 

Python éƒ¨åˆ† - ä¿å­˜æ¸²æŸ“æ•°æ®
æ–°å¢æ–‡ä»¶ï¼šdata_saver.py
import json
import os
from typing import List, Dict, Any
from dataclasses import asdict
from datetime import datetime

class TrainingDataSaver:
"""è®­ç»ƒæ•°æ®ä¿å­˜å™¨"""

def __init__(self, save_dir: str = "./training_data"):
    self.save_dir = save_dir
    os.makedirs(save_dir, exist_ok=True)
    self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    self.episodes_data: List[Dict[str, Any]] = []
    
def record_step(
    self, 
    episode: int,
    step: int,
    state: int,
    action: int,
    reward: float,
    maze_state: List[List[str]],
    agent_pos: List[int],
    info: Any,
    cumulative_reward: float
):
    """è®°å½•å•æ­¥æ•°æ®"""
    if episode >= len(self.episodes_data):
        self.episodes_data.append({
            "episode": episode,
            "steps": [],
            "total_reward": 0.0,
            "total_steps": 0,
            "success": False
        })
    
    action_names = ['UP', 'DOWN', 'LEFT', 'RIGHT']
    
    step_data = {
        "step": step,
        "state": state,
        "action": action,
        "action_name": action_names[action],
        "reward": reward,
        "cumulative_reward": cumulative_reward,
        "agent_pos": agent_pos,
        "maze_state": maze_state,
        "info": {
            "hit": info.hit if hasattr(info, 'hit') else "",
            "timeout": info.timeout if hasattr(info, 'timeout') else False
        }
    }
    
    self.episodes_data[episode]["steps"].append(step_data)

def finalize_episode(
    self,
    episode: int,
    total_reward: float,
    total_steps: int,
    success: bool,
    loss: float = None,
    agent_stats: Dict[str, Any] = None
):
    """å®Œæˆä¸€ä¸ªepisodeçš„è®°å½•"""
    if episode < len(self.episodes_data):
        self.episodes_data[episode].update({
            "total_reward": total_reward,
            "total_steps": total_steps,
            "success": success,
            "loss": loss,
            "agent_stats": agent_stats
        })

def save(self, agent_name: str):
    """ä¿å­˜åˆ°æ–‡ä»¶"""
    filename = f"{self.save_dir}/{self.session_id}_{agent_name}.json"
    
    data = {
        "session_id": self.session_id,
        "agent_name": agent_name,
        "timestamp": datetime.now().isoformat(),
        "total_episodes": len(self.episodes_data),
        "episodes": self.episodes_data
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {filename}")
    return filename
ä¿®æ”¹ä¸»æ–‡ä»¶ï¼Œåœ¨ MazeTrainer ç±»ä¸­æ·»åŠ ï¼š

åœ¨ MazeTrainer ç±»çš„ init æ–¹æ³•ä¸­æ·»åŠ 
class MazeTrainer:
def init(self, env: MazeEnv, agent: BaseAgent, save_data: bool = True) -> None:
self.env: MazeEnv = env
self.agent: BaseAgent = agent
self.episode_rewards: List[float] = []
self.episode_steps: List[int] = []
self.save_data = save_data
self.data_saver = TrainingDataSaver() if save_data else None

def train(
    self, 
    num_episodes: int = 500, 
    print_freq: int = 50, 
    render_freq: int = 100
) -> TrainingResult:
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {self.agent.get_stats().agent_type}")
    print(f"{'='*60}\n")
    
    start_time: float = time.time()
    
    for episode in range(num_episodes):
        state: int = self.env.reset()
        episode_reward: float = 0.0
        episode_steps: int = 0
        done: bool = False
        
        # æ”¶é›†ä¸€ä¸ªepisodeçš„æ•°æ®
        while not done:
            action: int = self.agent.select_action(state, training=True)
            step_result: StepResult = self.env.step(action)
            
            # ğŸ’¾ ä¿å­˜æ­¥éª¤æ•°æ®
            if self.data_saver:
                self.data_saver.record_step(
                    episode=episode,
                    step=episode_steps,
                    state=state,
                    action=action,
                    reward=step_result.reward,
                    maze_state=[row[:] for row in self.env.maze_map],  # æ·±æ‹·è´
                    agent_pos=list(self.env.agent_pos),
                    info=step_result.info,
                    cumulative_reward=episode_reward + step_result.reward
                )
            
            self.agent.store_transition(
                state, 
                action, 
                step_result.reward, 
                step_result.state, 
                step_result.done
            )
            
            state = step_result.state
            episode_reward += step_result.reward
            episode_steps += 1
            done = step_result.done
        
        # è®­ç»ƒ
        loss: Optional[float] = self.agent.train()
        
        # ğŸ’¾ å®Œæˆepisodeè®°å½•
        if self.data_saver:
            stats = self.agent.get_stats()
            self.data_saver.finalize_episode(
                episode=episode,
                total_reward=episode_reward,
                total_steps=episode_steps,
                success=episode_reward > 50,
                loss=loss,
                agent_stats=asdict(stats)
            )
        
        self.episode_rewards.append(episode_reward)
        self.episode_steps.append(episode_steps)
        
        # ... å…¶ä»–ä»£ç ä¿æŒä¸å˜ ...
    
    # ğŸ’¾ ä¿å­˜æ•°æ®
    if self.data_saver:
        agent_name = self.agent.get_stats().agent_type.replace(' ', '_')
        self.data_saver.save(agent_name)
    
    total_time: float = time.time() - start_time
    best_reward: float = float(max(self.episode_rewards))
    final_avg: float = float(np.mean(self.episode_rewards[-50:]))
    
    # ... è¿”å›ç»“æœ ...
TypeScript éƒ¨åˆ† - TUI æŸ¥çœ‹å™¨
åˆ›å»º Node.js é¡¹ç›®ç»“æ„ï¼š
mkdir rl-viewer
cd rl-viewer
npm init -y
npm install ink react @types/react @types/node
npm install -D @types/ink typescript tsx
package.json

{
"name": "rl-viewer",
"version": "1.0.0",
"type": "module",
"scripts": {
"dev": "tsx watch src/index.tsx",
"start": "tsx src/index.tsx",
"build": "tsc"
},
"dependencies": {
"ink": "^4.4.1",
"react": "^18.2.0"
},
"devDependencies": {
"@types/node": "^20.10.0",
"@types/react": "^18.2.0",
"tsx": "^4.7.0",
"typescript": "^5.3.0"
}
}
tsconfig.json

{
"compilerOptions": {
"target": "ES2022",
"module": "ES2022",
"moduleResolution": "node",
"jsx": "react",
"jsxImportSource": "react",
"esModuleInterop": true,
"strict": true,
"skipLibCheck": true,
"outDir": "./dist",
"baseUrl": "./src"
},
"include": ["src/**/*"]
}
src/types.ts

export interface StepInfo {
hit: string;
timeout: boolean;
}

export interface StepData {
step: number;
state: number;
action: number;
action_name: string;
reward: number;
cumulative_reward: number;
agent_pos: [number, number];
maze_state: string[][];
info: StepInfo;
}

export interface AgentStats {
agent_type: string;
buffer_size?: number;
epsilon?: number;
avg_loss?: number;
train_steps?: number;
current_buffer?: number;
ppo_epochs?: number;
avg_policy_loss?: number;
avg_value_loss?: number;
total_reuses?: number;
data_usage?: string;
}

export interface EpisodeData {
episode: number;
steps: StepData[];
total_reward: number;
total_steps: number;
success: boolean;
loss?: number;
agent_stats?: AgentStats;
}

export interface TrainingData {
session_id: string;
agent_name: string;
timestamp: string;
total_episodes: number;
episodes: EpisodeData[];
}
src/components/MazeRenderer.tsx

import React from 'react';
import { Box, Text } from 'ink';
import { StepData } from '../types.js';

interface MazeRendererProps {
stepData: StepData;
}

const CELL_SYMBOLS: Record<string, string> = {
R: 'â¬œ',
T: 'ğŸ’¥',
W: 'â¬›',
G: 'ğŸ¯',
B: 'ğŸ’',
};

const ACTION_ARROWS: Record<string, string> = {
UP: 'â¬†ï¸',
DOWN: 'â¬‡ï¸',
LEFT: 'â¬…ï¸',
RIGHT: 'â¡ï¸',
};

export const MazeRenderer: React.FC = ({ stepData }) => {
const renderMaze = () => {
const lines: JSX.Element[] = [];

stepData.maze_state.forEach((row, i) => {
  let rowStr = '';
  row.forEach((cell, j) => {
    if (i === stepData.agent_pos[0] && j === stepData.agent_pos[1]) {
      rowStr += 'ğŸ¤– ';
    } else {
      rowStr += (CELL_SYMBOLS[cell] || cell) + ' ';
    }
  });
  lines.push(<Text key={i}>{rowStr}</Text>);
});

return lines;
};

return (


{'='.repeat(40)}

{renderMaze()}

{'='.repeat(40)}



Step: {stepData.step} |
Action: {ACTION_ARROWS[stepData.action_name]} {stepData.action_name} |
Reward: = 0 ? 'green' : 'red'}>
{stepData.reward.toFixed(1)}



Cumulative Reward: = 0 ? 'green' : 'red'}>
{stepData.cumulative_reward.toFixed(1)}
|
Hit: {stepData.info.hit || 'none'}



);
};
src/components/EpisodeInfo.tsx

import React from 'react';
import { Box, Text } from 'ink';
import { EpisodeData } from '../types.js';

interface EpisodeInfoProps {
episode: EpisodeData;
isSelected: boolean;
}

export const EpisodeInfo: React.FC = ({ episode, isSelected }) => {
const bgColor = isSelected ? 'blue' : undefined;
const successIcon = episode.success ? 'âœ…' : 'âŒ';

return (


{successIcon} Episode {episode.episode}:
= 0 ? 'green' : 'red'}>
{' Reward: '}{episode.total_reward.toFixed(1)}

{' | Steps: '}{episode.total_steps}
{episode.loss !== null && episode.loss !== undefined &&
{' | Loss: '}{episode.loss.toFixed(4)}
}


);
};
src/components/AgentStatsPanel.tsx

import React from 'react';
import { Box, Text } from 'ink';
import { AgentStats } from '../types.js';

interface AgentStatsPanelProps {
stats?: AgentStats;
}

export const AgentStatsPanel: React.FC = ({ stats }) => {
if (!stats) return null;

return (

ğŸ“Š Agent Statistics
Type: {stats.agent_type}
{stats.buffer_size !== undefined && Buffer Size: {stats.buffer_size}}
{stats.epsilon !== undefined && Epsilon: {stats.epsilon.toFixed(3)}}
{stats.avg_loss !== undefined && Avg Loss: {stats.avg_loss.toFixed(4)}}
{stats.train_steps !== undefined && Train Steps: {stats.train_steps}}
{stats.ppo_epochs !== undefined && PPO Epochs: {stats.ppo_epochs}}
{stats.total_reuses !== undefined && Total Reuses: {stats.total_reuses}}
{stats.data_usage && Data Usage: {stats.data_usage}}

);
};
src/components/Viewer.tsx

import React, { useState, useEffect } from 'react';
import { Box, Text, useInput } from 'ink';
import { TrainingData } from '../types.js';
import { MazeRenderer } from './MazeRenderer.js';
import { EpisodeInfo } from './EpisodeInfo.js';
import { AgentStatsPanel } from './AgentStatsPanel.js';

interface ViewerProps {
data: TrainingData;
onExit: () => void;
}

export const Viewer: React.FC = ({ data, onExit }) => {
const [selectedEpisode, setSelectedEpisode] = useState(0);
const [selectedStep, setSelectedStep] = useState(0);

const currentEpisode = data.episodes[selectedEpisode];
const currentStep = currentEpisode?.steps[selectedStep];

useInput((input, key) => {
// ä¸Šä¸‹é”®ï¼šé€‰æ‹© episode
if (key.upArrow) {
setSelectedEpisode(prev => Math.max(0, prev - 1));
setSelectedStep(0);
} else if (key.downArrow) {
setSelectedEpisode(prev => Math.min(data.episodes.length - 1, prev + 1));
setSelectedStep(0);
}

// å·¦å³é”®ï¼šé€‰æ‹© step
else if (key.leftArrow) {
  setSelectedStep(prev => Math.max(0, prev - 1));
} else if (key.rightArrow) {
  setSelectedStep(prev => 
    Math.min(currentEpisode.steps.length - 1, prev + 1)
  );
}

// PageUp/PageDown: å¿«é€Ÿç¿»é¡µ
else if (key.pageUp) {
  setSelectedEpisode(prev => Math.max(0, prev - 10));
  setSelectedStep(0);
} else if (key.pageDown) {
  setSelectedEpisode(prev => Math.min(data.episodes.length - 1, prev + 10));
  setSelectedStep(0);
}

// Home/End: è·³åˆ°å¼€å§‹/ç»“æŸ
else if (input === 'h') {
  setSelectedEpisode(0);
  setSelectedStep(0);
} else if (input === 'e') {
  setSelectedEpisode(data.episodes.length - 1);
  setSelectedStep(0);
}

// q: é€€å‡º
else if (input === 'q') {
  onExit();
}
});

if (!currentEpisode || !currentStep) {
return Loading...;
}

return (

{/* æ ‡é¢˜ */}



ğŸ® RL Training Viewer - {data.agent_name}


Session: {data.session_id} | Total Episodes: {data.total_episodes}



  {/* ä¸»å†…å®¹åŒºåŸŸ */}
  <Box>
    {/* å·¦ä¾§ï¼šEpisode åˆ—è¡¨ */}
    <Box 
      flexDirection="column" 
      width={60} 
      borderStyle="round" 
      borderColor="yellow"
      padding={1}
      marginRight={2}
    >
      <Text bold color="yellow">ğŸ“‹ Episodes (â†‘â†“ to navigate, PgUp/PgDn for fast scroll)</Text>
      <Box flexDirection="column" height={20} overflowY="hidden">
        {data.episodes
          .slice(Math.max(0, selectedEpisode - 10), selectedEpisode + 10)
          .map((ep) => (
            <EpisodeInfo
              key={ep.episode}
              episode={ep}
              isSelected={ep.episode === selectedEpisode}
            />
          ))
        }
      </Box>
    </Box>

    {/* å³ä¾§ï¼šStep æ¸²æŸ“ */}
    <Box flexDirection="column" flexGrow={1}>
      <Box borderStyle="round" borderColor="cyan" padding={1} marginBottom={1}>
        <Text bold color="cyan">
          ğŸ¬ Step {selectedStep + 1}/{currentEpisode.steps.length} (â†â†’ to navigate)
        </Text>
      </Box>
      
      <MazeRenderer stepData={currentStep} />
      
      <AgentStatsPanel stats={currentEpisode.agent_stats} />
    </Box>
  </Box>

  {/* åº•éƒ¨å¿«æ·é”®æç¤º */}
  <Box borderStyle="round" borderColor="gray" padding={1} marginTop={1}>
    <Text dimColor>
      âŒ¨ï¸  Controls: â†‘â†“ Episode | â†â†’ Step | PgUp/PgDn Fast scroll | H Home | E End | Q Quit
    </Text>
  </Box>
</Box>
);
};
src/index.tsx

#!/usr/bin/env node
import React, { useState, useEffect } from 'react';
import { render, Box, Text } from 'ink';
import { readFileSync } from 'fs';
import { resolve } from 'path';
import { TrainingData } from './types.js';
import { Viewer } from './components/Viewer.js';

const App: React.FC = () => {
const [data, setData] = useState<TrainingData | null>(null);
const [error, setError] = useState<string | null>(null);

useEffect(() => {
try {
const filePath = process.argv[2];

  if (!filePath) {
    setError('Usage: npm start <path-to-training-data.json>');
    return;
  }

  const fullPath = resolve(filePath);
  const fileContent = readFileSync(fullPath, 'utf-8');
  const jsonData: TrainingData = JSON.parse(fileContent);
  
  setData(jsonData);
} catch (err) {
  setError(`Error loading file: ${err}`);
}
}, []);

if (error) {
return (

âŒ {error}

);
}

if (!data) {
return (

â³ Loading training data...

);
}

return <Viewer data={data} onExit={() => process.exit(0)} />;
};

render();
3. ä½¿ç”¨è¯´æ˜
Python ç«¯

è¿è¡Œè®­ç»ƒï¼ˆä¼šè‡ªåŠ¨ä¿å­˜æ•°æ®ï¼‰
python your_main_file.py
TypeScript ç«¯

è¿›å…¥æŸ¥çœ‹å™¨ç›®å½•
cd rl-viewer

å®‰è£…ä¾èµ–
npm install

è¿è¡ŒæŸ¥çœ‹å™¨
npm start ../training_data/20240115_143022_DQN_(Off-Policy).json
å¿«æ·é”®
â†‘â†“: é€‰æ‹© Episode
â†â†’: é€‰æ‹© Step
PgUp/PgDn: å¿«é€Ÿç¿»é¡µ (Â±10 episodes)
H: è·³åˆ°ç¬¬ä¸€ä¸ª Episode
E: è·³åˆ°æœ€åä¸€ä¸ª Episode
Q: é€€å‡º
4. æ•ˆæœé¢„è§ˆ
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ® RL Training Viewer - DQN_(Off-Policy) â”‚
â”‚ Session: 20240115_143022 | Total Episodes: 300 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ ğŸ“‹ Episodes â”‚ â”‚ ğŸ¬ Step 15/47 â”‚
â”‚ âœ… Episode 0: Reward: 85.0 â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â”‚ âŒ Episode 1: Reward: -25.0 â”‚ â•­â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•®
â”‚ ğŸ”µ Episode 2: Reward: 100.0 â”‚ â”‚ â¬› â¬› â¬› â¬› â¬› â¬› â¬› â¬› â”‚
â”‚ âœ… Episode 3: Reward: 90.0 â”‚ â”‚ â¬œ â¬œ ğŸ¤– ğŸ’¥ â¬œ â¬œ â¬› ğŸ¯ â”‚
â”‚ ... â”‚ â”‚ â¬› ğŸ’ â¬› â¬› â¬› â¬œ â¬œ â¬› â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â•°â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¯
Step: 15 | Action: â¡ï¸ RIGHT
Reward: -1.0 | Hit: road
è¿™æ ·å°±å®ç°äº†å®Œæ•´çš„è®­ç»ƒæ•°æ®è®°å½•å’Œå¯è§†åŒ–æŸ¥çœ‹åŠŸèƒ½ï¼